using System;
using System.Linq;

public class NeuralNetwork
{
    private int inputSize;
    private int hiddenSize;
    private int outputSize;
    private double[,] weightsInputHidden;
    private double[,] weightsHiddenOutput;
    private Random random;

    public NeuralNetwork(int inputSize, int hiddenSize, int outputSize)
    {
        this.inputSize = inputSize;
        this.hiddenSize = hiddenSize;
        this.outputSize = outputSize;
        weightsInputHidden = new double[inputSize, hiddenSize];
        weightsHiddenOutput = new double[hiddenSize, outputSize];
        random = new Random();

        InitializeWeights();
    }

    private void InitializeWeights()
    {
        for (int i = 0; i < inputSize; i++)
        {
            for (int j = 0; j < hiddenSize; j++)
            {
                weightsInputHidden[i, j] = random.NextDouble() * 2 - 1; // Random weights between -1 and 1
            }
        }

        for (int i = 0; i < hiddenSize; i++)
        {
            for (int j = 0; j < outputSize; j++)
            {
                weightsHiddenOutput[i, j] = random.NextDouble() * 2 - 1; // Random weights between -1 and 1
            }
        }
    }

    private double ReLU(double x)
    {
        return Math.Max(0, x);
    }

    private double[] Softmax(double[] x)
    {
        double max = x.Max();
        double[] exps = x.Select(val => Math.Exp(val - max)).ToArray();
        double expsSum = exps.Sum();
        return exps.Select(val => val / expsSum).ToArray();
    }

    public double[] FeedForward(double[] inputs)
    {
        double[] hiddenLayerValues = new double[hiddenSize];
        double[] outputLayerValues = new double[outputSize];

        // Calculate values for hidden layer
        for (int i = 0; i < hiddenSize; i++)
        {
            double sum = 0;
            for (int j = 0; j < inputSize; j++)
            {
                sum += inputs[j] * weightsInputHidden[j, i];
            }
            hiddenLayerValues[i] = ReLU(sum);
        }

        // Calculate values for output layer
        for (int i = 0; i < outputSize; i++)
        {
            double sum = 0;
            for (int j = 0; j < hiddenSize; j++)
            {
                sum += hiddenLayerValues[j] * weightsHiddenOutput[j, i];
            }
            outputLayerValues[i] = sum;
        }

        return Softmax(outputLayerValues);
    }

    public void Train(double[] inputs, double[] targets, double learningRate)
    {
        // Feedforward
        double[] hiddenLayerValues = new double[hiddenSize];
        double[] outputLayerValues = new double[outputSize];

        // Calculate values for hidden layer
        for (int i = 0; i < hiddenSize; i++)
        {
            double sum = 0;
            for (int j = 0; j < inputSize; j++)
            {
                sum += inputs[j] * weightsInputHidden[j, i];
            }
            hiddenLayerValues[i] = ReLU(sum);
        }

        // Calculate values for output layer
        for (int i = 0; i < outputSize; i++)
        {
            double sum = 0;
            for (int j = 0; j < hiddenSize; j++)
            {
                sum += hiddenLayerValues[j] * weightsHiddenOutput[j, i];
            }
            outputLayerValues[i] = sum;
        }

        // Softmax activation for output layer
        outputLayerValues = Softmax(outputLayerValues);

        // Backpropagation
        double[] outputErrors = new double[outputSize];
        for (int i = 0; i < outputSize; i++)
        {
            outputErrors[i] = targets[i] - outputLayerValues[i];
        }

        double[] hiddenErrors = new double[hiddenSize];
        for (int i = 0; i < hiddenSize; i++)
        {
            double error = 0;
            for (int j = 0; j < outputSize; j++)
            {
                error += outputErrors[j] * weightsHiddenOutput[i, j];
            }
            hiddenErrors[i] = error;
        }

        // Update weights using gradient descent
        for (int i = 0; i < inputSize; i++)
        {
            for (int j = 0; j < hiddenSize; j++)
            {
                weightsInputHidden[i, j] += learningRate * inputs[i] * (hiddenErrors[j] > 0 ? 1 : 0) * hiddenErrors[j];
            }
        }

        for (int i = 0; i < hiddenSize; i++)
        {
            for (int j = 0; j < outputSize; j++)
            {
                weightsHiddenOutput[i, j] += learningRate * hiddenLayerValues[i] * outputErrors[j];
            }
        }
    }
}

class Program
{
    static void Main(string[] args)
    {
        // Sample usage of the neural network
        NeuralNetwork neuralNetwork = new NeuralNetwork(2, 3, 2);

        // Training data
        double[][] inputs = {
            new double[]{0, 0},
            new double[]{0, 1},
            new double[]{1, 0},
            new double[]{1, 1}
        };

        double[][] targets = {
            new double[]{1, 0},
            new double[]{0, 1},
            new double[]{0, 1},
            new double[]{1, 0}
        };

        // Training the network
        double learningRate = 0.1;
        int epochs = 10000;
        for (int epoch = 0; epoch < epochs; epoch++)
        {
            for (int i = 0; i < inputs.Length; i++)
            {
                neuralNetwork.Train(inputs[i], targets[i], learningRate);
            }
        }

        // Test the trained network
        foreach (var input in inputs)
        {
            double[] output = neuralNetwork.FeedForward(input);
            Console.WriteLine($"Input: [{input[0]}, {input[1]}], Output: [{output[0]}, {output[1]}]");
        }
    }
}
